# Refer to:
# https://github.com/VICO-UoE/DatasetCondensation/issues/21 for k-center strategy 
# https://github.com/VICO-UoE/DatasetCondensation/issues/15 for herding strategy
import os
import argparse
from re import L
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.utils
from tqdm import tqdm, trange
from utils import get_dataset, get_network, get_eval_pool, evaluate_synset, get_time, DiffAugment, TensorDataset, epoch, get_loops, match_loss, ParamDiffAug, Conv3DNet
import wandb
import copy
import random
from reparam_module import ReparamModule
import warnings

warnings.filterwarnings("ignore", category=DeprecationWarning)

import distill_utils

def main(args):
    torch.set_num_threads(8)
    print("CUDNN STATUS: {}".format(torch.backends.cudnn.enabled))

    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'
    args.distributed = torch.cuda.device_count() > 1

    model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)

    channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader= get_dataset(args.dataset, args.data_path)

    if args.preload:
        print("Preloading dataset")
        video_all = []
        label_all = []
        for i in trange(len(dst_train)):
            _ = dst_train[i]
            video_all.append(_[0])
            label_all.append(_[1])
        video_all = torch.stack(video_all)
        label_all = torch.tensor(label_all)
        dst_train = torch.utils.data.TensorDataset(video_all, label_all)

    labels_all = label_all if args.preload else dst_train.labels
    indices_class = [[] for c in range(num_classes)]

    print("BUILDING DATASET")
    for i, lab in tqdm(enumerate(labels_all)):
        indices_class[lab].append(i)
    labels_all = torch.tensor(labels_all, dtype=torch.long, device="cpu")

    def get_indices_class(c):
        idx = indices_class[c]
        imgs = torch.cat([dst_train[i][0].unsqueeze(0) for i in idx], 0)
        return imgs.to(args.device)
    
    net = get_network(args.model, channel, num_classes, im_size).to(args.device)  # get a random model
    net.train()
    for param in list(net.parameters()):
        param.requires_grad = False

    # load pretrained model
    print("Loading pretrained model")
    if args.pretrained_path is not None:
        net.load_state_dict(torch.load(args.pretrained_path))    
    net.eval()
    embed = net.module.embed if args.distributed else net.embed

    image_syn = torch.randn(size=(num_classes*args.ipc, args.frames, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=False, device=args.device)
    label_syn = torch.tensor(np.stack([np.ones(args.ipc)*i for i in range(0, num_classes)]), dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]
    
    if args.method == 'k-center':
        for c in range(num_classes):
            print("Generating synthetic data for class {}".format(c))
            imgs = get_indices_class(c)
            features = embed(imgs)
            mean = torch.mean(features, dim=0, keepdim=True)
            dis = torch.norm(features - mean, dim=1)
            rank = torch.argsort(dis) 
            idx_centers = rank[:1].tolist() 
            for i in range(args.ipc-1):
                feature_centers = features[idx_centers]
                dis_center = torch.norm(features - feature_centers, dim=-1)
                dis_min, _ = torch.min(dis_center, dim=-1)
                id_max = torch.argmax(dis_min).item()
                idx_centers.append(id_max)
            image_syn[c*args.ipc:(c+1)*args.ipc] = imgs[idx_centers]
        print("Synthetic data generated by k-center")
    elif args.method == 'herding':
        for c in range(num_classes):
            print("Generating synthetic data for class {}".format(c))
            imgs = get_indices_class(c)
            features = embed(imgs)
            mean = torch.mean(features, dim=0, keepdim=True)
            idx_selected = []
            idx_left = np.arange(features.shape[0]).tolist()

            for i in range(args.ipc):
                if len(idx_selected) > 0:
                    det = mean*(i+1) - torch.sum(features[idx_selected], dim=0)
                else:
                    det = mean*(i+1)
                dis = torch.norm(det-features[idx_left], dim=1)
                idx = torch.argmin(dis).item()
                idx_selected.append(idx_left[idx])
                del idx_left[idx]
            image_syn[c*args.ipc:(c+1)*args.ipc] = imgs[idx_selected]
    else:
        raise NotImplementedError

    # print("Evaluating synthetic data")
    # evaluate_synset(net, image_syn, label_syn, args.device)
    for model_eval in model_eval_pool:
        accs_test = []
        accs_train = []
        for it_eval in range(args.num_eval):
            net_eval = get_network(model_eval, channel, num_classes, im_size).to(args.device)  # get a random model
            image_syn_eval, label_syn_eval = image_syn.detach().clone(), label_syn.detach().clone() # avoid any unaware modification
            _, acc_train, acc_test, acc_per_cls = evaluate_synset(it_eval, net_eval, image_syn_eval, label_syn_eval, testloader, args, mode='none',test_freq=100)
            print('acc_test:',acc_test)
            accs_test.append(acc_test)
            accs_train.append(acc_train)
        accs_test = np.array(accs_test)
        accs_train = np.array(accs_train)
        acc_test_mean = np.mean(accs_test)
        acc_test_std = np.std(accs_test)
        print('acc_test_mean:',acc_test_mean)
        print('acc_test_std:',acc_test_std)

        '''wandb.log({'Accuracy/{}'.format(model_eval): acc_test_mean}, step=it)
        wandb.log({'Max_Accuracy/{}'.format(model_eval): best_acc[model_eval]}, step=it)
        wandb.log({'Std/{}'.format(model_eval): acc_test_std}, step=it)
        wandb.log({'Max_Std/{}'.format(model_eval): best_std[model_eval]}, step=it)'''


        

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Parameter Processing')
    parser.add_argument('--dataset', type=str, default='miniUCF101', help='dataset')

    parser.add_argument('--method', type=str, default='k-center', help='k-center or herding')
    parser.add_argument('--model', type=str, default='ConvNet3D', help='model')

    parser.add_argument('--ipc', type=int, default=1, help='image(s) per class')

    parser.add_argument('--eval_mode', type=str, default='S',
                        help='eval_mode, check utils.py for more info')

    parser.add_argument('--num_eval', type=int, default=5, help='how many networks to evaluate on')

    parser.add_argument('--epoch_eval_train', type=int, default=1000,
                        help='epochs to train a model with synthetic data')
    parser.add_argument('--lr_net', type=float, default=0.001, help='learning rate for network')

    parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')

    parser.add_argument('--data_path', type=str, default='distill_utils/data', help='dataset path')
    parser.add_argument('--pretrained_path', type=str, default=None, help='pretrained model path')
    parser.add_argument('--num_workers', type=int, default=8, help='')
    parser.add_argument('--save_path',type=str, default='.', help='path to save')
    parser.add_argument('--frames', type=int, default=16, help='')
    parser.add_argument('--preload', action='store_true', help='preload dataset')


    args = parser.parse_args()

    main(args)